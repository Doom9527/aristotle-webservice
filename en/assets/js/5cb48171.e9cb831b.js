"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[24],{4741:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"caching","title":"Caching","description":"[//]: # (Copyright 2024 Paion Data)","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/caching.md","sourceDirName":".","slug":"/caching","permalink":"/aristotle-webservice/en/docs/caching","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/caching.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Caching"},"sidebar":"tutorialSidebar","previous":{"title":"Filtering by Properties","permalink":"/aristotle-webservice/en/docs/filtering"}}');var s=i(4848),t=i(8453);const r={sidebar_position:5,title:"Caching"},c=void 0,l={},d=[{value:"Handling Long-Running Queries",id:"handling-long-running-queries",level:2},{value:"Multi-Level Cache Architecture",id:"multi-level-cache-architecture",level:3},{value:"Caching Strategy and Implementation",id:"caching-strategy-and-implementation",level:3},{value:"Configuration Example",id:"configuration-example",level:4},{value:"Code Snippet",id:"code-snippet",level:4},{value:"Advantages of Multi-Level Caching",id:"advantages-of-multi-level-caching",level:3},{value:"Handling Timeout Queries",id:"handling-timeout-queries",level:2},{value:"Distributed Cache Loader Design",id:"distributed-cache-loader-design",level:3},{value:"Key Code Snippet",id:"key-code-snippet",level:4},{value:"Redis Data Structure Example",id:"redis-data-structure-example",level:3}];function o(e){const n={admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["Aristotle is designed to serve knowledge graphs with billions of nodes and relationships. Facing such a large-scale dataset, how to efficiently support CRUD operations, especially the common ",(0,s.jsx)(n.em,{children:"expand"})," operation, is a core challenge in system design. Under massive data, expand operations often lead to:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Excessive query latency"}),"\n",(0,s.jsx)(n.li,{children:"Query timeouts (e.g., memory overflow)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This section combines practical engineering experience to introduce how Aristotle solves the above problems through multi-level caching and distributed cache loading mechanisms."}),"\n",(0,s.jsx)(n.h2,{id:"handling-long-running-queries",children:"Handling Long-Running Queries"}),"\n",(0,s.jsx)(n.p,{children:"In high-concurrency and large-data scenarios, even small-scale subgraph expansions can put great pressure on the database, resulting in slow queries. Therefore, Aristotle adopts a multi-level caching mechanism combining local and distributed caches, balancing query performance and system scalability."}),"\n",(0,s.jsx)(n.h3,{id:"multi-level-cache-architecture",children:"Multi-Level Cache Architecture"}),"\n",(0,s.jsx)(n.p,{children:"The system uses Caffeine as the local cache and Redis as the distributed cache, forming the following layered structure:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Application   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Caffeine    \u2502 \u2190 Local cache (L1, ultra-low latency)\n\u2502   (JVM RAM)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Redis       \u2502 \u2190 Distributed cache (L2, multi-node sharing)\n\u2502 (Remote store)\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Neo4j       \u2502 \u2190 Data source\n\u2502 (Database)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Caffeine"}),": Stores frequently accessed hot data, providing the fastest access speed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Redis"}),": Stores precomputed subgraph data, supports distributed access and high capacity."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Configurable Switches"}),": Each cache type can be enabled/disabled independently, flexibly adapting to different business needs."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"caching-strategy-and-implementation",children:"Caching Strategy and Implementation"}),"\n",(0,s.jsx)(n.p,{children:"Uses the classic Cache-Aside Pattern:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"On query, check Caffeine first. If not hit, check Redis. If still not hit, query the database and write back to the cache."}),"\n",(0,s.jsx)(n.li,{children:"On data update or deletion, actively clear both local and distributed caches to ensure consistency."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"configuration-example",children:"Configuration Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"spring:\n  read-cache:\n    enabled: true          # Enable Caffeine cache\n    num-subgraphs: 500     # Max cache entries\n  redis:\n    enabled: true          # Enable Redis cache\n    host: 127.0.0.1\n    port: 6379\n"})}),"\n",(0,s.jsx)(n.admonition,{title:"Configurable Mechanism",type:"info",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"You can flexibly control cache enable/disable via configuration files."}),"\n",(0,s.jsx)(n.li,{children:"Supports custom parameters such as max cache entries and expiration time."}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"code-snippet",children:"Code Snippet"}),"\n",(0,s.jsx)(n.p,{children:"Take Spring Boot as an example, Caffeine and Redis switches:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'@Configuration\npublic class CaffeineConfig {\n    @Value("${spring.read-cache.enabled:true}")\n    private boolean cacheEnabled;\n    @Bean\n    public Cache<String, GraphVO> graphCache() {\n        if (!cacheEnabled) {\n            return Caffeine.newBuilder().build(); // Empty cache\n        }\n        return Caffeine.newBuilder()\n                .maximumSize(500)\n                .expireAfterWrite(2, TimeUnit.MINUTES)\n                .build();\n    }\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'@Configuration\n@ConditionalOnProperty(value = "spring.redis.enabled", havingValue = "true")\npublic class RedisConfig {\n    // Only effective when Redis is enabled\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"advantages-of-multi-level-caching",children:"Advantages of Multi-Level Caching"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Extreme Performance"}),": Local cache hits first, greatly reducing remote access and database pressure."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"High Availability"}),": Redis supports distributed deployment, data can be shared across multiple nodes."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexible Scalability"}),": Cache strategies and capacity can be dynamically adjusted according to business needs."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"handling-timeout-queries",children:"Handling Timeout Queries"}),"\n",(0,s.jsx)(n.p,{children:'For timeout issues caused by large data volumes, the system adopts a "precomputation + distributed cache loader" solution. Through an independent cache loading service, batch compute and cache subgraph expansion results, greatly improving subsequent query efficiency.'}),"\n",(0,s.jsx)(n.h3,{id:"distributed-cache-loader-design",children:"Distributed Cache Loader Design"}),"\n",(0,s.jsx)(n.p,{children:"Taking Neo4j as an example, the process is as follows:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Batch Traverse Nodes"}),": Scheduled tasks batch traverse all nodes, use BFS to compute max expansion depth."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Store Results in Redis"}),": Store each node's expansion subgraph and depth info in Redis as cache for subsequent queries."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Checkpoint & Progress Management"}),": Supports checkpoint resume to avoid redundant computation and improve task robustness."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"key-code-snippet",children:"Key Code Snippet"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'@Slf4j\n@Service\npublic class CacheLoaderService {\n    @Autowired\n    private RedisTemplate<String, Object> redisTemplate;\n    @Autowired\n    private Neo4jService neo4jService;\n    public synchronized void startLoading() {\n        // Checkpoint resume\n        Integer start = (Integer) redisTemplate.opsForValue().get("task:progress");\n        if (start == null) start = 0;\n        // Batch loading and BFS expansion\n        // ...\n        // Store to Redis\n        redisTemplate.opsForValue().set("graph:" + node.getUuid() + ":data", graph);\n        redisTemplate.opsForValue().set("graph:" + node.getUuid() + ":maxDepth", graph.getMaxDepth());\n    }\n}\n'})}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"The distributed cache loader can be deployed independently, supports scheduled batch preheating, and is suitable for efficient expansion queries on large-scale knowledge graphs."})}),"\n",(0,s.jsx)(n.h3,{id:"redis-data-structure-example",children:"Redis Data Structure Example"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"graph:{nodeUuid}:data"}),": Stores the expansion subgraph data of the node"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"graph:{nodeUuid}:maxDepth"}),": Stores the max expansion depth of the node"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"task:progress"}),": Records the progress of cache loading tasks, supports checkpoint resume"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"Through the above multi-level cache and distributed cache loading mechanism, Aristotle can efficiently handle high-concurrency expansion queries and timeout issues on large-scale knowledge graphs, greatly improving system stability and response speed."}),"\n",(0,s.jsx)(n.p,{children:"For more details on cache configuration and advanced usage, please refer to the relevant source code and configuration documentation."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>c});var a=i(6540);const s={},t=a.createContext(s);function r(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);